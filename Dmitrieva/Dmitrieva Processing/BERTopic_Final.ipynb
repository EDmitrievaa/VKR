{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWZ0e87EjHIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fbb4c9-8502-4d29-bc6b-9d0ed28b35e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# PROPER FIX FOR pymorphy2 in Python 3.11+\n",
        "!pip install -q pymorphy3  # New fork compatible with Python 3.11+\n",
        "from pymorphy3 import MorphAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Russian lemmatizer\n",
        "morph = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "rld_4PV0RSvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Special cases and abbreviations\n",
        "SPECIAL_CASES = {\n",
        "    'сша': 'США',\n",
        "    'сизо': 'СИЗО',\n",
        "    'мчс': 'МЧС',\n",
        "    'цб': 'ЦБ',\n",
        "    'дтп': 'ДТП',\n",
        "    'хамас': 'ХАМАС',\n",
        "    'нато': 'НАТО',\n",
        "    'ндфл': 'НДФЛ',\n",
        "    'россии': 'Россия',\n",
        "    'хезболлы': 'Хезболла',\n",
        "    'росавиации': 'Росавиация',\n",
        "    'дону': 'Дон',\n",
        "    'украины': 'Украина',\n",
        "    'украина': 'Украина',\n",
        "    'подписаться': '',\n",
        "    'на': '',\n",
        "    'это': '',\n",
        "    'в': 'в',\n",
        "    'с': 'с'\n",
        "}\n",
        "\n",
        "ABBREVIATIONS = {'США', 'МЧС', 'ЦБ', 'ДТП', 'ХАМАС', 'СИЗО'}"
      ],
      "metadata": {
        "id": "xJWWkyh6zjgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_word(word, prev_word=None):\n",
        "    \"\"\"Enhanced word normalization with proper nominative case handling\"\"\"\n",
        "    lower_word = word.lower()\n",
        "\n",
        "    # Handle special cases first\n",
        "    if lower_word in SPECIAL_CASES:\n",
        "        return SPECIAL_CASES[lower_word]\n",
        "\n",
        "    # Handle numbers with units\n",
        "    if word.replace('.', '').isdigit() and prev_word:\n",
        "        if prev_word.lower() in ['рублей', 'млн', 'млрд', 'кв']:\n",
        "            return word\n",
        "\n",
        "    try:\n",
        "        parsed = morph.parse(word)[0]\n",
        "\n",
        "        # Only convert to nominative for inflectable words\n",
        "        if any(tag in parsed.tag for tag in ['NOUN', 'ADJF', 'ADJS', 'VERB', 'PRTF', 'GRND']):\n",
        "            # Get all possible normal forms\n",
        "            normal_forms = {p.normal_form for p in morph.parse(word)}\n",
        "\n",
        "            # Try to convert to nominative\n",
        "            try:\n",
        "                nominative = parsed.inflect({'nomn'}).word\n",
        "                # Check if nominative form exists in possible normal forms\n",
        "                if nominative.lower() in {nf.lower() for nf in normal_forms}:\n",
        "                    result = nominative\n",
        "                else:\n",
        "                    result = parsed.normal_form\n",
        "            except:\n",
        "                result = parsed.normal_form\n",
        "\n",
        "            # Preserve original capitalization for proper nouns\n",
        "            if word.istitle() and not any(c.isupper() for c in word[1:]):\n",
        "                return result.capitalize()\n",
        "            return result\n",
        "\n",
        "        return word\n",
        "    except:\n",
        "        return word"
      ],
      "metadata": {
        "id": "KBx9JAUZ6ESw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_phrase(words):\n",
        "    \"\"\"Build natural-sounding phrases from words\"\"\"\n",
        "    if not words:\n",
        "        return \"\"\n",
        "\n",
        "    phrase = []\n",
        "    skip_next = False\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue\n",
        "\n",
        "        # Handle number+unit combinations\n",
        "        if word.isdigit() and i < len(words)-1:\n",
        "            next_word = words[i+1].lower()\n",
        "            if next_word in ['рублей', 'млн', 'млрд', 'кв']:\n",
        "                phrase.append(f\"{word} {next_word}\")\n",
        "                skip_next = True\n",
        "                continue\n",
        "\n",
        "        # Handle currency amounts\n",
        "        if word == 'млн' and i > 0 and words[i-1].isdigit():\n",
        "            phrase[-1] = f\"{words[i-1]} {word}\"\n",
        "            continue\n",
        "\n",
        "        phrase.append(word)\n",
        "\n",
        "    # Join and clean the phrase\n",
        "    phrase_text = ' '.join(phrase)\n",
        "\n",
        "    # Add prepositions where needed\n",
        "    phrase_text = re.sub(r'(\\s[вс])\\s', r'\\1 ', phrase_text)\n",
        "\n",
        "    return phrase_text"
      ],
      "metadata": {
        "id": "tUPy1b9e6HnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_topic_name(name):\n",
        "    \"\"\"Main cleaning function for topic names\"\"\"\n",
        "\n",
        "    # Extract meaningful part\n",
        "    topic_part = name.split('____')[-1] if '____' in name else name.split('_', 1)[-1]\n",
        "\n",
        "    # Split and clean words\n",
        "    words = re.split(r'_|\\s+', topic_part)\n",
        "    words = [w.strip() for w in words if w.strip() and w.lower() != 'nan']\n",
        "\n",
        "    # Process words\n",
        "    processed_words = []\n",
        "    seen_lemmas = set()\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        # Skip empty or redundant words\n",
        "        if not word or word.lower() in {'на', 'за', 'подписаться', 'nan'}:\n",
        "            continue\n",
        "\n",
        "        prev_word = processed_words[-1] if processed_words else None\n",
        "        normalized = normalize_word(word, prev_word)\n",
        "\n",
        "        if not normalized:  # Skip if normalized to empty string\n",
        "            continue\n",
        "\n",
        "        lemma = morph.parse(word)[0].normal_form if word.isalpha() else word\n",
        "\n",
        "        if lemma not in seen_lemmas:\n",
        "            seen_lemmas.add(lemma)\n",
        "            processed_words.append(normalized)\n",
        "\n",
        "    # Build natural phrase\n",
        "    topic_text = construct_phrase(processed_words[:3])  # Limit to a number of components\n",
        "\n",
        "    # Final capitalization and cleaning\n",
        "    if topic_text:\n",
        "        topic_text = topic_text[0].upper() + topic_text[1:]\n",
        "        topic_text = re.sub(r'(\\d)\\s([а-яё])', r'\\1_\\2', topic_text)\n",
        "        topic_text = topic_text.replace('  ', ' ').strip()\n",
        "\n",
        "    return topic_text"
      ],
      "metadata": {
        "id": "1j1G_zqx6KXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process_names(df):\n",
        "    \"\"\"Apply final polishing to topic names\"\"\"\n",
        "    df['Clean_Name'] = df['Clean_Name'].str.replace(r'\\s+', ' ', regex=True)\n",
        "    df['Clean_Name'] = df['Clean_Name'].apply(\n",
        "        lambda x: re.sub(r'(\\d) (\\D)', r'\\1_\\2', x) if isinstance(x, str) else x\n",
        "    )\n",
        "    return df"
      ],
      "metadata": {
        "id": "37Szkkh66OWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    df = pd.read_csv(\"rbc_BERTopic.csv\", sep=';')\n",
        "\n",
        "    # Apply cleaning\n",
        "    df['Clean_Name'] = df['Name'].apply(clean_topic_name)\n",
        "    df = post_process_names(df)\n",
        "\n",
        "    # Move Representative_Docs to the last column position\n",
        "    if 'Representative_Docs' in df.columns:\n",
        "        # Get all columns except Representative_Docs, then add it at the end\n",
        "        cols = [col for col in df.columns if col != 'Representative_Docs'] + ['Representative_Docs']\n",
        "        df = df[cols]\n",
        "        print(\"\\nMoved 'Representative_Docs' to last column position\")\n",
        "    else:\n",
        "        print(\"\\n'Representative_Docs' column not found in DataFrame\")\n",
        "\n",
        "    # Show results\n",
        "    print(\"\\nFinal cleaned topic names:\")\n",
        "    print(df.head(10))\n",
        "\n",
        "    # Save cleaned data to new CSV file\n",
        "    output_filename = \"rbc_BERTopic_cleaned_v3.csv\"\n",
        "    df.to_csv(output_filename,\n",
        "              sep=';',\n",
        "              index=False,\n",
        "              encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nCleaned data successfully saved to '{output_filename}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D7S43lO6QaB",
        "outputId": "9c6754f5-a0f5-44de-faa0-8bf252d1b222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Moved 'Representative_Docs' to last column position\n",
            "\n",
            "Final cleaned topic names:\n",
            "   Topic  Count                                         Name  \\\n",
            "0     -1   7044                         -1____сша_это_россии   \n",
            "1      0   1914              0_nan_nan nan_дону nan_nan сизо   \n",
            "2      1    421  1_спорт_канал спорт_подписаться канал_канал   \n",
            "3      2    341             2_израиля_хамас_израиль_хезболлы   \n",
            "4      3    315          3_пост_должность_должности_отставку   \n",
            "5      4    299                        4_пожара_мчс_пожар_кв   \n",
            "6      5    281    5_ограничения_росавиации_аэропорту_полеты   \n",
            "7      6    226        6_вино_вина_алкоголя_подписаться вино   \n",
            "8      7    219                7_делу_взятки_млн руб_бывшего   \n",
            "9      8    212         8_недвижимость_жилья_недвижимости_кв   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  ['__', 'сша', 'это', 'россии', 'заявил', 'года...   \n",
            "1  ['nan', 'nan nan', 'дону nan', 'nan сизо', 'си...   \n",
            "2  ['спорт', 'канал спорт', 'подписаться канал', ...   \n",
            "3  ['израиля', 'хамас', 'израиль', 'хезболлы', 'н...   \n",
            "4  ['пост', 'должность', 'должности', 'отставку',...   \n",
            "5  ['пожара', 'мчс', 'пожар', 'кв', 'площадь', 'п...   \n",
            "6  ['ограничения', 'росавиации', 'аэропорту', 'по...   \n",
            "7  ['вино', 'вина', 'алкоголя', 'подписаться вино...   \n",
            "8  ['делу', 'взятки', 'млн руб', 'бывшего', 'арес...   \n",
            "9  ['недвижимость', 'жилья', 'недвижимости', 'кв'...   \n",
            "\n",
            "                        Clean_Name  \\\n",
            "0                       США Россия   \n",
            "1                         Дон СИЗО   \n",
            "2                      Спорт канал   \n",
            "3           Израиль ХАМАС Хезболла   \n",
            "4          Пост должность отставка   \n",
            "5                     Пожар МЧС кв   \n",
            "6  Ограничение Росавиация аэропорт   \n",
            "7                    Вино алкоголь   \n",
            "8                  Дело взятка млн   \n",
            "9            Недвижимость жильё кв   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  ['представители сша, россии и украины на полях...  \n",
            "1                              ['nan', 'nan', 'nan']  \n",
            "2  ['сборная россии выиграла( восьмой матч подряд...  \n",
            "3  ['израиль намерен возобновить боевые действия(...  \n",
            "4  ['путин предложил первому вице-спикеру совета ...  \n",
            "5  ['в подольске загорелось производственное здан...  \n",
            "6  ['аэропорт казани временно не принимает и не о...  \n",
            "7  ['безалкогольное вино: альтернатива или нет?( ...  \n",
            "8  ['следственный комитет сообщил о предъявлении ...  \n",
            "9  ['аналитики зафиксировали снижение( арендных с...  \n",
            "\n",
            "Cleaned data successfully saved to 'rbc_BERTopic_cleaned_v3.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XVYFxtapJW9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}