{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf4af2b",
      "metadata": {
        "id": "6cf4af2b",
        "outputId": "7e4795ce-05c8-45c7-b8f6-c8283ba579d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.3)\n",
            "Requirement already satisfied: deeppavlov in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.7.0)\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: torchcrf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.1.0)\n",
            "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/alyona/Library/Python/3.10/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tqdm<4.65.0,>=4.42.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (4.64.1)\n",
            "Requirement already satisfied: uvicorn<0.19.0,>=0.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (0.18.3)\n",
            "Requirement already satisfied: wheel in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (0.45.1)\n",
            "Requirement already satisfied: scipy==1.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (1.10.0)\n",
            "Requirement already satisfied: pydantic<2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (1.10.22)\n",
            "Requirement already satisfied: fastapi<=0.89.1,>=0.47.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (0.89.1)\n",
            "Requirement already satisfied: pybind11==2.10.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (2.10.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (2.32.3)\n",
            "Requirement already satisfied: prometheus-client<=1.16.0,>=0.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (0.21.1)\n",
            "Requirement already satisfied: scikit-learn<1.1.0,>=0.24 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (1.0.2)\n",
            "Requirement already satisfied: filelock<3.10.0,>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deeppavlov) (3.9.1)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: starlette==0.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fastapi<=0.89.1,>=0.47.0->deeppavlov) (0.22.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (3.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/alyona/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/alyona/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<1.1.0,>=0.24->deeppavlov) (3.6.0)\n",
            "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from uvicorn<0.19.0,>=0.13.0->deeppavlov) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas deeppavlov torch torchcrf nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c29da03",
      "metadata": {
        "id": "6c29da03",
        "outputId": "19badef7-1b3a-4dc1-8d84-2d8b012599a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking dependencies...\n",
            "pandas already installed\n",
            "deeppavlov already installed\n",
            "torch already installed\n",
            "Installing torchcrf...\n",
            "Requirement already satisfied: torchcrf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchcrf) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchcrf) (2.2.2)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->torchcrf) (3.1.6)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->torchcrf) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->torchcrf) (2025.3.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->torchcrf) (3.9.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->torchcrf) (4.13.2)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->torchcrf) (1.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchcrf) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchcrf) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nltk already installed\n",
            "stanza already installed\n",
            "Loading DeepPavlov model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-05 14:11:33.932 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_mult_torch_crf.tar.gz download because of matching hashes\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DeepPavlov failed: No module named 'torchcrf'\n",
            "Using Stanza fallback...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 28.4MB/s]                    \n",
            "2025-05-05 14:11:39 INFO: Downloaded file to /Users/alyona/stanza_resources/resources.json\n",
            "2025-05-05 14:11:39 INFO: Downloading default packages for language: ru (Russian) ...\n",
            "2025-05-05 14:11:44 INFO: File exists: /Users/alyona/stanza_resources/ru/default.zip\n",
            "2025-05-05 14:12:02 INFO: Finished downloading models and saved to /Users/alyona/stanza_resources\n",
            "2025-05-05 14:12:02 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 6.98MB/s]                    \n",
            "2025-05-05 14:12:03 INFO: Downloaded file to /Users/alyona/stanza_resources/resources.json\n",
            "2025-05-05 14:12:04 INFO: Loading these models for language: ru (Russian):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | syntagrus |\n",
            "| ner       | wikiner   |\n",
            "=========================\n",
            "\n",
            "2025-05-05 14:12:04 INFO: Using device: cpu\n",
            "2025-05-05 14:12:04 INFO: Loading: tokenize\n",
            "2025-05-05 14:12:05 INFO: Loading: ner\n",
            "2025-05-05 14:12:21 INFO: Done loading processors!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using stanza model\n",
            "\n",
            "Success! Results saved to: /Users/alyona/entities_output.csv\n",
            "Sample output:\n",
            "                                        news_content       entity_text  \\\n",
            "0  **Разворот в 2025 году: ждать или нет? **\\n\\nБ...               ДКП   \n",
            "1  **Разворот в 2025 году: ждать или нет? **\\n\\nБ...     @selfinvestor   \n",
            "2  **Разворот в 2025 году: ждать или нет? **\\n\\nБ...        **Разворот   \n",
            "3  **Разворот в 2025 году: ждать или нет? **\\n\\nБ...  ВТБМоиИнвестиции   \n",
            "4  **Разворот в 2025 году: ждать или нет? **\\n\\nБ...               ВТБ   \n",
            "\n",
            "  entity_type  \n",
            "0        MISC  \n",
            "1        MISC  \n",
            "2        MISC  \n",
            "3         ORG  \n",
            "4         ORG  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import ssl\n",
        "\n",
        "def fix_ssl():\n",
        "    \"\"\"Fix SSL certificate verification issues\"\"\"\n",
        "    try:\n",
        "        _create_unverified_https_context = ssl._create_unverified_context\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    else:\n",
        "        ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "def check_dependencies():\n",
        "    \"\"\"Check and install required packages\"\"\"\n",
        "    required = {\n",
        "        'pandas': 'pandas',\n",
        "        'deeppavlov': 'deeppavlov',\n",
        "        'torch': 'torch',\n",
        "        'torchcrf': 'torchcrf',\n",
        "        'nltk': 'nltk',\n",
        "        'stanza': 'stanza'\n",
        "    }\n",
        "\n",
        "    print(\"Checking dependencies...\")\n",
        "    for pkg, install_name in required.items():\n",
        "        try:\n",
        "            __import__(pkg)\n",
        "            print(f\"{pkg} already installed\")\n",
        "        except ImportError:\n",
        "            print(f\"Installing {pkg}...\")\n",
        "            subprocess.run([sys.executable, '-m', 'pip', 'install', '--user', install_name], check=True)\n",
        "\n",
        "def load_model():\n",
        "    \"\"\"Try loading models with fallbacks\"\"\"\n",
        "    # Try DeepPavlov first\n",
        "    try:\n",
        "        from deeppavlov import configs\n",
        "        from deeppavlov.core.commands.infer import build_model\n",
        "        print(\"Loading DeepPavlov model...\")\n",
        "        return build_model(configs.ner.ner_ontonotes_bert_mult, download=True), 'deeppavlov'\n",
        "    except Exception as e:\n",
        "        print(f\"DeepPavlov failed: {e}\")\n",
        "\n",
        "    # Fallback to Stanza\n",
        "    try:\n",
        "        import stanza\n",
        "        print(\"Using Stanza fallback...\")\n",
        "        stanza.download('ru')\n",
        "        return stanza.Pipeline('ru', processors='tokenize,ner'), 'stanza'\n",
        "    except Exception as e:\n",
        "        print(f\"Stanza failed: {e}\")\n",
        "        raise ImportError(\"Could not load any NER model\")\n",
        "\n",
        "def clean_entity_text(entity):\n",
        "    \"\"\"Normalize entity text\"\"\"\n",
        "    return re.sub(r'\\s+', '', entity).replace('ё', 'е').replace('Ё', 'Е')\n",
        "\n",
        "def extract_entities(text, model, model_type):\n",
        "    \"\"\"Extract entities based on model type\"\"\"\n",
        "    if not text or pd.isna(text):\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        if model_type == 'deeppavlov':\n",
        "            results = model([text])[0]\n",
        "            entities = defaultdict(list)\n",
        "            current_entity, current_tag = [], None\n",
        "\n",
        "            for word, tag in results:\n",
        "                if tag == \"O\":\n",
        "                    if current_entity:\n",
        "                        cleaned = clean_entity_text(\"\".join(current_entity))\n",
        "                        if len(cleaned) > 1:\n",
        "                            entities[current_tag].append(cleaned)\n",
        "                        current_entity, current_tag = [], None\n",
        "                else:\n",
        "                    entity_tag = tag.split(\"-\")[-1]\n",
        "                    if tag.startswith(\"B-\") or entity_tag != current_tag:\n",
        "                        if current_entity:\n",
        "                            cleaned = clean_entity_text(\"\".join(current_entity))\n",
        "                            if len(cleaned) > 1:\n",
        "                                entities[current_tag].append(cleaned)\n",
        "                        current_entity, current_tag = [word], entity_tag\n",
        "                    else:\n",
        "                        current_entity.append(word)\n",
        "\n",
        "            if current_entity:\n",
        "                cleaned = clean_entity_text(\"\".join(current_entity))\n",
        "                if len(cleaned) > 1:\n",
        "                    entities[current_tag].append(cleaned)\n",
        "\n",
        "            return dict(entities)\n",
        "\n",
        "        elif model_type == 'stanza':\n",
        "            doc = model(text)\n",
        "            entities = defaultdict(list)\n",
        "            for ent in doc.ents:\n",
        "                cleaned = clean_entity_text(ent.text)\n",
        "                if len(cleaned) > 1:\n",
        "                    entities[ent.type].append(cleaned)\n",
        "            return dict(entities)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return {}\n",
        "\n",
        "def get_output_path():\n",
        "    \"\"\"Get a writable output path\"\"\"\n",
        "    # Try current directory first\n",
        "    if os.access(\".\", os.W_OK):\n",
        "        return \"entities_output.csv\"\n",
        "\n",
        "    # Try home directory\n",
        "    home_path = os.path.expanduser(\"~/entities_output.csv\")\n",
        "    try:\n",
        "        with open(home_path, 'w') as f:\n",
        "            pass\n",
        "        os.remove(home_path)\n",
        "        return home_path\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Try desktop as last resort\n",
        "    desktop_path = os.path.expanduser(\"~/Desktop/entities_output.csv\")\n",
        "    try:\n",
        "        with open(desktop_path, 'w') as f:\n",
        "            pass\n",
        "        os.remove(desktop_path)\n",
        "        return desktop_path\n",
        "    except:\n",
        "        raise PermissionError(\"Could not find a writable location for output file\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Fix SSL first\n",
        "        fix_ssl()\n",
        "\n",
        "        # Check and install dependencies\n",
        "        check_dependencies()\n",
        "\n",
        "        # Load model\n",
        "        model, model_type = load_model()\n",
        "        print(f\"Using {model_type} model\")\n",
        "\n",
        "        # Load data\n",
        "        try:\n",
        "            df = pd.read_csv(\"/Users/alyona/Desktop/rbc.csv\")\n",
        "        except UnicodeDecodeError:\n",
        "            df = pd.read_csv(\"/Users/alyona/Desktop/rbc.csv\", encoding=\"utf-8\")\n",
        "        except:\n",
        "            df = pd.read_csv(\"/Users/alyona/Desktop/rbc.csv\", encoding=\"latin1\")\n",
        "\n",
        "        # Process data\n",
        "        results = []\n",
        "        for _, row in df.iterrows():\n",
        "            message = str(row.get('message', ''))\n",
        "            if pd.isna(message):\n",
        "                continue\n",
        "\n",
        "            entities = extract_entities(message, model, model_type)\n",
        "\n",
        "            for entity_type, entity_list in entities.items():\n",
        "                for entity in set(entity_list):\n",
        "                    results.append({\n",
        "                        'news_content': message[:500] + \"...\" if len(message) > 500 else message,\n",
        "                        'entity_text': entity,\n",
        "                        'entity_type': entity_type,\n",
        "                        'time': row.get('time'),\n",
        "                        'sha': row.get('sha')\n",
        "                    })\n",
        "\n",
        "        # Save results to a writable location\n",
        "        output_path = get_output_path()\n",
        "        final_df = pd.DataFrame(results).drop_duplicates(\n",
        "            subset=['sha', 'entity_text', 'entity_type'],\n",
        "            keep='first'\n",
        "        )\n",
        "        final_df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "        print(f\"\\nSuccess! Results saved to: {output_path}\")\n",
        "        print(\"Sample output:\")\n",
        "        print(final_df[['news_content', 'entity_text', 'entity_type']].head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Fatal error: {e}\")\n",
        "        print(\"\\nTroubleshooting steps:\")\n",
        "        print(\"1. Try running VSCode as administrator\")\n",
        "        print(\"2. Or run these commands in terminal:\")\n",
        "        print(\"   mkdir -p ~/ner_output\")\n",
        "        print(\"   chmod 777 ~/ner_output\")\n",
        "        print(\"3. Then modify the script to save to ~/ner_output/entities_output.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a361964",
      "metadata": {
        "id": "3a361964"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}